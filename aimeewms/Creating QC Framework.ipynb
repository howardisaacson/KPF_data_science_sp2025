{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3190d37a-6c05-4faa-b9a3-ffff2e4d8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from scipy.ndimage import convolve1d\n",
    "from kpfpipe.models.level1 import KPF1\n",
    "from modules.Utils.utils import DummyLogger, styled_text\n",
    "from modules.Utils.kpf_parse import HeaderParse, get_datetime_obsid, get_kpf_level, get_data_products_expected\n",
    "from modules.Utils.kpf_parse import get_data_products_L0, get_data_products_L1\n",
    "from modules.quicklook.src.analyze_guider import AnalyzeGuider\n",
    "from modules.quicklook.src.analyze_2d import Analyze2D\n",
    "from modules.quicklook.src.analyze_l1 import AnalyzeL1\n",
    "from modules.calibration_lookup.src.alg import GetCalibrations\n",
    "from modules.Utils.kpf_parse import HeaderParse, get_data_products_L2\n",
    "from kpfpipe.models.level2 import KPF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3392a28f-bf95-45c0-8560-6046e37edff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzeL2:\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This class contains functions to analyze L2 spectra (storing them\n",
    "        as attributes) and functions to plot the results.\n",
    "\n",
    "    Arguments:\n",
    "        L2 - an L2 object\n",
    "\n",
    "    Attributes:\n",
    "        name - name of source (e.g., 'Bias', 'Etalon', '185144')\n",
    "        ObsID - observation  ID (e.g. 'KP.20230704.02326.27')\n",
    "        header - header of the PRIMARY extension of the L2 object\n",
    "        rv_header - header of the RV extension\n",
    "    \n",
    "    To do:\n",
    "        Add plot showing combined CCF - https://github.com/Keck-DataReductionPipelines/KPF-Pipeline/issues/940\n",
    "        Add plot showing correlations between per-order RVs and per-chip RVs and overall RVs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, L2, logger=None):\n",
    "        if logger:\n",
    "            self.logger = logger\n",
    "            self.logger.debug('Initializing AnalyzeL2 object')\n",
    "        else:\n",
    "            self.logger = None\n",
    "        self.L2 = copy.deepcopy(L2)\n",
    "        self.df_RV = self.L2['RV']\n",
    "        self.n_green_orders = 35\n",
    "        self.n_red_orders   = 32\n",
    "        primary_header = HeaderParse(L2, 'PRIMARY')\n",
    "        self.header = primary_header.header\n",
    "        self.name = primary_header.get_name()\n",
    "        if primary_header.get_name(use_star_names=False) in ['Star', 'Sun']:\n",
    "            self.is_star = True\n",
    "        else:\n",
    "            self.is_star = False\n",
    "        self.ObsID = primary_header.get_obsid()\n",
    "        self.rv_header = HeaderParse(L2, 'RV').header\n",
    "        self.df_RVs = self.L2['RV'] # Table of RVs per order and orderlet\n",
    "        self.data_products = get_data_products_L2(self.L2)\n",
    "        self.green_present = 'Green' in self.data_products\n",
    "        self.red_present = 'Red' in self.data_products\n",
    "        self.texp = self.header['ELAPSED']\n",
    "\n",
    "        self.compute_statistics()\n",
    "        \n",
    "        \n",
    "    def compute_statistics(self):\n",
    "        \"\"\"\n",
    "        Compute various metrics of dispersion of the per-order BJD values\n",
    "        \"\"\"\n",
    "        # compute weighted Barycentric RV correction\n",
    "        x = self.df_RV['Bary_RVC']\n",
    "        w = self.df_RV['CCF Weights']\n",
    "        self.CCFBCV = np.sum(w * x) / np.sum(w)\n",
    "\n",
    "        # compute weighted BJD (this should be computed elsewhere and read from the L2 header)\n",
    "        x = self.df_RV['CCFBJD']\n",
    "        w = self.df_RV['CCF Weights']\n",
    "        self.CCFBJD = np.sum(w * x) / np.sum(w)\n",
    "\n",
    "        # compute per-order BJD differences\n",
    "        self.df_RV['Delta_CCFBJD'] = self.df_RV['CCFBJD'].copy()\n",
    "        self.df_RV['Delta_CCFBJD'] -= self.CCFBJD\n",
    "        #    compute weighted standard deviation\n",
    "        x = self.df_RV['Delta_CCFBJD']\n",
    "        w = self.df_RV['CCF Weights']\n",
    "        nonzero_mask = w != 0\n",
    "        wmean = np.sum(w * x) / np.sum(w)\n",
    "        var_pop = np.sum(w * (x - wmean)**2) / np.sum(w) # weighted variance\n",
    "        self.Delta_CCFBJD_weighted_std = np.sqrt(var_pop) * 24*60*60  # seconds\n",
    "        self.Delta_CCFBJD_weighted_range = (x[nonzero_mask].max() - x[nonzero_mask].min()) * 24*60*60  # seconds\n",
    "\n",
    "        # compute per-order Barycentric RV differences\n",
    "        self.df_RV['Delta_Bary_RVC'] = self.df_RV['Bary_RVC'].copy()\n",
    "        self.df_RV['Delta_Bary_RVC'] -= self.CCFBCV\n",
    "        #    compute weighted standard deviation\n",
    "        x = self.df_RV['Delta_Bary_RVC']\n",
    "        wmean = np.sum(w * x) / np.sum(w)\n",
    "        var_pop = np.sum(w * (x - wmean)**2) / np.sum(w) # weighted variance\n",
    "        self.Delta_Bary_RVC_weighted_std = np.sqrt(var_pop) * 1000 # m/s\n",
    "        self.Delta_Bary_RVC_weighted_range = (x[nonzero_mask].max() - x[nonzero_mask].min()) * 1000 # m/s\n",
    "        # compute per-order percent change difference from weighted Barycentric RV correction\n",
    "        if self.CCFBCV != 0:\n",
    "            self.df_RV['Perc_Delta_Bary_RVC'] = (self.df_RV['Delta_Bary_RVC'].copy() / self.CCFBCV) * 100 # percent\n",
    "        else:\n",
    "            self.df_RV['Perc_Delta_Bary_RVC'] = self.df_RV['Delta_Bary_RVC'].copy() * 0 # just set to zero\n",
    "        # compute maximum and minimum percent change difference (for only orders with nonzero weights)\n",
    "        x = self.df_RV['Perc_Delta_Bary_RVC']\n",
    "        self.Max_Perc_Delta_Bary_RV = x[nonzero_mask].max()\n",
    "        self.Min_Perc_Delta_Bary_RV = x[nonzero_mask].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d73ab6f-9e8e-4eb7-80c7-4b734da6afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains classes for KPF data quality control (QC).  Various QC metrics are defined in\n",
    "class QCDefinitions.  Other classes QCL0, QC2D, QCL1, and QCL2 contain methods to compute QC values,\n",
    "which are with the QC metrics, for specific data products, and then store them in the primary header\n",
    "of the corresponding KPF object (which will be saved to a FITS file).  Normally QC values are stored\n",
    "headers, but storage in the KPF pipeline-operations database may be set up later by the database\n",
    "administrator, depending upon the special requirements for some QC metrics.\n",
    "\"\"\"\n",
    "\n",
    "iam = 'quality_control'\n",
    "version = '1.3'\n",
    "\n",
    "\"\"\"\n",
    "The following are methods common across data levels, which are given at the beginning\n",
    "of this module, before the QC classes are defined.\n",
    "\n",
    "Includes helper functions that compute statistics of data of arbitrary shape.\n",
    "\"\"\"\n",
    "\n",
    "#####################################\n",
    "# Module helper functions.\n",
    "#####################################\n",
    "\n",
    "def what_am_i():\n",
    "    print('Software version:',iam + ' ' + version)\n",
    "\n",
    "def compute_clip_corr(n_sigma):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute a correction factor to properly reinflate the variance after it is\n",
    "    naturally diminished via data-clipping.  Employ a simple Monte Carlo method\n",
    "    and standard normal deviates to simulate the data-clipping and obtain the\n",
    "    correction factor.\n",
    "    \"\"\"\n",
    "\n",
    "    var_trials = []\n",
    "    for x in range(0,10):\n",
    "        a = np.random.normal(0.0, 1.0, 1000000)\n",
    "        med = np.median(a, axis=0)\n",
    "        p16 = np.percentile(a, 16, axis=0)\n",
    "        p84 = np.percentile(a, 84, axis=0)\n",
    "        sigma = 0.5 * (p84 - p16)\n",
    "        mdmsg = med - n_sigma * sigma\n",
    "        b = np.less(a,mdmsg)\n",
    "        mdpsg = med + n_sigma * sigma\n",
    "        c = np.greater(a,mdpsg)\n",
    "        mask = np.any([b,c],axis=0)\n",
    "        mx = ma.masked_array(a, mask)\n",
    "        var = ma.getdata(mx.var(axis=0))\n",
    "        var_trials.append(var)\n",
    "\n",
    "    np_var_trials = np.array(var_trials)\n",
    "    avg_var_trials = np.mean(np_var_trials)\n",
    "    std_var_trials = np.std(np_var_trials)\n",
    "    corr_fact = 1.0 / avg_var_trials\n",
    "\n",
    "    return corr_fact\n",
    "\n",
    "def avg_data_with_clipping(data_array,n_sigma = 3.0):\n",
    "\n",
    "    \"\"\"\n",
    "    Statistics with outlier rejection (n-sigma data-trimming), ignoring NaNs, across all data array dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    cf = compute_clip_corr(n_sigma)\n",
    "    sqrtcf = np.sqrt(cf)\n",
    "\n",
    "    a = np.array(data_array)\n",
    "\n",
    "    med = np.nanmedian(a)\n",
    "    p16 = np.nanpercentile(a,16)\n",
    "    p84 = np.nanpercentile(a,84)\n",
    "    sigma = 0.5 * (p84 - p16)\n",
    "    mdmsg = med - n_sigma * sigma\n",
    "    b = np.less(a,mdmsg)\n",
    "    mdpsg = med + n_sigma * sigma\n",
    "    c = np.greater(a,mdpsg)\n",
    "    d = np.where(np.isnan(a),True,False)\n",
    "    mask = b | c | d\n",
    "    mx = ma.masked_array(a, mask)\n",
    "    avg = ma.getdata(mx.mean())\n",
    "    std = ma.getdata(mx.std()) * sqrtcf\n",
    "    cnt = ma.getdata(mx.count())\n",
    "\n",
    "    return avg,std,cnt\n",
    "\n",
    "\n",
    "def check_all_qc_keywords(kpf_object,fname,input_master_type='all',logger=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Method to check all QC keywords in PRIMARY header of FITS object.\n",
    "\n",
    "    Agnostic of data level; checks all QC keywords in PRIMARY header\n",
    "    that have assigned value for qc_definitions.fits_keyword_fail_value[dict_key]\n",
    "    (which are not None).  Failure is declared only for the relevant master type.\n",
    "    Currently only integer fail_values are handled.\n",
    "\n",
    "    Returns:\n",
    "        qc_fail - a boolean signifying that the QC failed (True) for at least one of the QC keywords or not (False).\n",
    "    \"\"\"\n",
    "\n",
    "    logger = logger if logger is not None else DummyLogger()\n",
    "\n",
    "    qc_fail = False\n",
    "\n",
    "    qc_definitions = QCDefinitions()\n",
    "\n",
    "    dict_keys_list = qc_definitions.fits_keywords.keys()\n",
    "\n",
    "    for dict_key in dict_keys_list:\n",
    "\n",
    "        kw = qc_definitions.fits_keywords[dict_key]\n",
    "        master_types = qc_definitions.master_types[dict_key]\n",
    "\n",
    "        try:\n",
    "            fail_value = qc_definitions.fits_keyword_fail_value[dict_key]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if fail_value is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            kw_value = kpf_object.header['PRIMARY'][kw]\n",
    "            if kw_value == fail_value:\n",
    "                logger.debug('--------->quality_control: check_all_qc_keywords: fname,kw,kw_value,fail_value = {},{},{},{}'.format(fname,kw,kw_value,fail_value))\n",
    "                for master_type in master_types:\n",
    "                    if input_master_type.lower() == master_type.lower() or master_type.lower() == 'all' or input_master_type.lower() == 'all':\n",
    "                        qc_fail = True\n",
    "                        break\n",
    "\n",
    "                return qc_fail\n",
    "\n",
    "        except KeyError as err:\n",
    "            continue\n",
    "\n",
    "    return qc_fail\n",
    "\n",
    "\n",
    "def execute_all_QCs(kpf_object, data_level, logger=None):\n",
    "    \"\"\"\n",
    "    Method to loop over all QC tests for the data level of the input KPF object\n",
    "    (an L0, 2D, L1, or L2 object).  This method is useful for testing (e.g.,\n",
    "    in a Jupyter Notebook).  To run the QCs in a recipe, use methods in\n",
    "    quality_control_framework.py\n",
    "\n",
    "    Args:\n",
    "        kpf_object - a KPF object (L0, 2D, L1, or L2)\n",
    "        data_type -\n",
    "\n",
    "    Attributes:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        kpf_object - the input kpf_object with QC keywords added\n",
    "    \"\"\"\n",
    "\n",
    "    logger = logger if logger is not None else DummyLogger()\n",
    "\n",
    "    #data_level = get_kpf_level(kpf_object)\n",
    "\n",
    "    # Define QC object\n",
    "    if data_level == 'L0':\n",
    "        qc_obj = QCL0(kpf_object)\n",
    "    elif data_level == '2D':\n",
    "        qc_obj = QC2D(kpf_object)\n",
    "    elif data_level == 'L1':\n",
    "        qc_obj = QCL1(kpf_object)\n",
    "    elif data_level == 'L2':\n",
    "        qc_obj = QCL2(kpf_object)\n",
    "    else:\n",
    "        print('data_level is not L0, 2D, L1, or L2.  Exiting.')\n",
    "\n",
    "    if data_level != None:\n",
    "\n",
    "        # Get a list of QC method names appropriate for the data level\n",
    "        qc_names = []\n",
    "        for qc_name in qc_obj.qcdefinitions.names:\n",
    "            if data_level in qc_obj.qcdefinitions.kpf_data_levels[qc_name]:\n",
    "                qc_names.append(qc_name)\n",
    "\n",
    "        # Run the QC tests and add result keyword to header\n",
    "        primary_header = HeaderParse(kpf_object, 'PRIMARY')\n",
    "        is_good = 1\n",
    "        this_spectrum_type = primary_header.get_name(use_star_names=False)\n",
    "        logger.info(f'Spectrum type: {this_spectrum_type}')\n",
    "        for qc_name in qc_names:\n",
    "            try:\n",
    "                spectrum_types = qc_obj.qcdefinitions.spectrum_types[qc_name]\n",
    "                if (this_spectrum_type in spectrum_types) or ('all' in spectrum_types):\n",
    "                    if len(qc_obj.qcdefinitions.required_data_products[qc_name]) == 0:\n",
    "                        all_required_data_products_present = True\n",
    "                    else:\n",
    "                        data_products_expected = get_data_products_expected(kpf_object, data_level)\n",
    "                        data_products_required = qc_obj.qcdefinitions.required_data_products[qc_name]\n",
    "                        all_required_data_products_present = all(element in data_products_expected for element in data_products_required)\n",
    "                    if all_required_data_products_present:\n",
    "                        text_running_qc = styled_text('Running QC', style=\"Bold\", color=\"Magenta\")\n",
    "                        text_qc_name = styled_text(qc_name, style=\"Bold\", color=\"Blue\")\n",
    "                        text_qc_keyword = styled_text(qc_obj.qcdefinitions.fits_keywords[qc_name], style=\"Bold\", color=\"Blue\")\n",
    "                        logger.info(f'{text_running_qc}: {text_qc_name} ({text_qc_keyword}; {qc_obj.qcdefinitions.descriptions[qc_name]})')\n",
    "                        method = getattr(qc_obj, qc_name) # get method with the name 'qc_name'\n",
    "                        qc_value = method() # evaluate method\n",
    "                        if qc_value == True:\n",
    "                            text_qc_value = styled_text(qc_value, style=\"Bold\", color=\"Green\")\n",
    "                        elif qc_value == False:\n",
    "                            text_qc_value = styled_text(qc_value, style=\"Bold\", color=\"Red\")\n",
    "                            is_good = 0\n",
    "                        if qc_obj.qcdefinitions.fits_keywords[qc_name] == 'KPFERA':\n",
    "                            logger.info(f'Result: {styled_text(\"KPFERA\", style=\"Bold\", color=\"Blue\")}={styled_text(qc_value, style=\"Bold\")}')\n",
    "                        else:\n",
    "                            logger.info(f'QC result: {text_qc_value} (True = pass)')\n",
    "                        qc_obj.add_qc_keyword_to_header(qc_name, qc_value)\n",
    "                    else:\n",
    "                        logger.info(f'Not running QC: {qc_name} ({qc_obj.qcdefinitions.descriptions[qc_name]}) because {data_products_required} not in list of expected data products({data_products_expected})')\n",
    "                else:\n",
    "                    logger.info(f'Not running QC: {qc_name} ({qc_obj.qcdefinitions.descriptions[qc_name]}) because {this_spectrum_type} not in list of spectrum types: {spectrum_types}')\n",
    "\n",
    "            except KeyError as e:\n",
    "                logger.info(f\"KeyError: {e}\")\n",
    "                pass\n",
    "\n",
    "            except AttributeError as e:\n",
    "                logger.info(f'Method {qc_name} does not exist in qc_obj or another AttributeError occurred: {e}')\n",
    "                pass\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.info(f'An error occurred when executing {qc_name}:', str(e))\n",
    "                pass\n",
    "\n",
    "        kpf_object.header['PRIMARY']['ISGOOD'] = (is_good, \"QC: all other QC tests passed\")\n",
    "\n",
    "    return kpf_object\n",
    "\n",
    "\n",
    "def check_all_QC_keywords_present(kpf_object, logger=None):\n",
    "    \"\"\"\n",
    "    Method to determine if all QC tests have been run on the input kpf_object\n",
    "    by examining it's keywords.  The method determines the data_level for\n",
    "    kpf_object and checks for keywords of that level and lower, e.g., for\n",
    "    data_level = 'L1', the method checks for keywords in levels 'L0', '2D',\n",
    "    and 'L1'.\n",
    "\n",
    "    Args:\n",
    "        kpf_object - a KPF object (L0, 2D, L1, or L2)\n",
    "        logger - Python logger object; if None, the DummyLogger is used\n",
    "\n",
    "    Returns:\n",
    "        kpf_object - the input kpf_object with QC keywords added\n",
    "    \"\"\"\n",
    "\n",
    "    logger = logger if logger is not None else DummyLogger()\n",
    "    data_level = get_kpf_level(kpf_object)\n",
    "    primary_header = HeaderParse(kpf_object, 'PRIMARY')\n",
    "    this_spectrum_type = primary_header.get_name(use_star_names=False)\n",
    "\n",
    "    if data_level == 'L0':\n",
    "        data_levels = data_levels = ['L0']\n",
    "    if data_level == '2D':\n",
    "        data_levels = data_levels = ['L0', '2D']\n",
    "    if data_level == 'L1':\n",
    "        data_levels = data_levels = ['L0', '2D', 'L1']\n",
    "    if data_level == 'L2':\n",
    "        data_levels = data_levels = ['L0', '2D', 'L1', 'L2']\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "class QCDefinitions:\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This class defines QC metrics in a standard format.\n",
    "        Dictionaries are used to associate unique metric names with various metric metadata.\n",
    "        Modify this class to add new metrics.  Do not remove any metrics (we deprecate metrics\n",
    "        simply by not using them any more).  When adding metrics to this class, ensure the length\n",
    "        of the names list is equal to the number of dictionary entries.\n",
    "\n",
    "    Class Attributes:\n",
    "        names (list of strings): Each element is a unique and descriptive name for the metric.  No spaces allowed.\n",
    "        descriptions (dictionary of strings): Each dictionary entry specifies a short description of the metric\n",
    "            Try to keep it under 50 characters for brevity (this is not enforced but recommended).\n",
    "        kpf_data_levels (dictionary of lists of strings): Each entry specifies the set of KPF data levels for the test.\n",
    "            Possible values in the list: 'L0', '2D', 'L1', 'L2'\n",
    "        data_types (dictionary of strings): Each entry specifies the Python data type of the metric.\n",
    "            Only string, int, float are allowed.  Use 0/1 for boolean.\n",
    "        spectrum_types (dictionary of arrays of strings): Each entry specifies the types of spectra that the metric will be applied to.\n",
    "            Possible strings in array: 'all', 'Bias', 'Dark', 'Flat', 'Wide Flat', 'LFC', 'Etalon', 'ThAr', 'UNe', 'Sun', 'Star', <starname>\n",
    "        master_types (dictionary of arrays of strings): Each entry specifies the types of masters where the QC check is relevant.  If the QC fails for an exposure, it is not added to the master stack.\n",
    "            Possible strings in array: 'all', 'Bias', 'Dark', 'Flat', 'Wide Flat', 'LFC', 'Etalon', 'ThAr', 'UNe'\n",
    "        required_data_products (dictionary of arrays of strings): specifies if data products are needed to perform check\n",
    "            if = [], then no required data products; other possible values are from get_data_products_L0, etc.\n",
    "        fits_keywords (dictionary of strings): Each entry specifies the FITS-header keyword for the metric.\n",
    "            Must be 8 characters or less, following the FITS standard.\n",
    "        fits_comments (dictionary of strings): Each entry specifies the FITS-header comment for the metric.\n",
    "            Must be a short string for brevity (say, under 35 characters), following the FITS standard.\n",
    "        db_columns (dictionary of strings): Each entry specifies either database_table.column if applicable,\n",
    "            or None if not.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logger=None):\n",
    "\n",
    "        self.logger = logger if logger is not None else DummyLogger()\n",
    "\n",
    "        self.names = []\n",
    "        self.descriptions = {}\n",
    "        self.kpf_data_levels = {}\n",
    "        self.data_types = {}\n",
    "        self.spectrum_types = {}\n",
    "        self.master_types = {} # if = [], then the QC test is not relevant for the construction of any masters\n",
    "        self.required_data_products = {} # if = [], then no required data products; other possible values: Green, Red, CaHK, ExpMeter, Guider, Telemetry, Config, Receipt, Pyrheliometer\n",
    "        self.fits_keywords = {}\n",
    "        self.fits_comments = {}\n",
    "        self.db_columns = {}\n",
    "        self.fits_keyword_fail_value = {}\n",
    "\n",
    "        # Define QC metrics\n",
    "        name1 = 'not_junk'\n",
    "        self.names.append(name1)\n",
    "        self.descriptions[name1] = 'File is not in list of junk files.'\n",
    "        self.kpf_data_levels[name1] = ['L0', '2D', 'L1', 'L2']\n",
    "        self.data_types[name1] = 'int'\n",
    "        self.spectrum_types[name1] = ['all', ] # Need trailing comma to make list hashable\n",
    "        self.master_types[name1] = ['all', ]\n",
    "        self.required_data_products[name1] = [] # no required data products\n",
    "        self.fits_keywords[name1] = 'NOTJUNK'\n",
    "        self.fits_comments[name1] = 'QC: Not in list of junk files'\n",
    "        self.db_columns[name1] = None\n",
    "        self.fits_keyword_fail_value[name1] = 0\n",
    "\n",
    "        name36 = 'L2_barycentric_rv_percent_change'\n",
    "        self.names.append(name36)\n",
    "        self.kpf_data_levels[name36] = ['L2']\n",
    "        self.descriptions[name36] = 'Check non-zero-weight spectral orders BCV percent changes from weighted average are within an acceptable range.'\n",
    "        self.data_types[name36] = 'int'\n",
    "        self.spectrum_types[name36] = ['all', ]\n",
    "        self.master_types[name36] = []\n",
    "        self.required_data_products[name36] = [] # no required data products\n",
    "        self.fits_keywords[name36] = 'PCBCV'\n",
    "        self.fits_comments[name36] = 'QC: PCBCV values within acceptable range'\n",
    "        self.db_columns[name36] = None\n",
    "        self.fits_keyword_fail_value[name36] = 0\n",
    "\n",
    "        # Integrity checks\n",
    "        if len(self.names) != len(self.kpf_data_levels):\n",
    "            raise ValueError(\"Length of kpf_data_levels list does not equal number of entries in descriptions dictionary.\")\n",
    "\n",
    "        if len(self.names) != len(self.descriptions):\n",
    "            raise ValueError(\"Length of names list does not equal number of entries in descriptions dictionary.\")\n",
    "\n",
    "        if len(self.names) != len(self.data_types):\n",
    "            raise ValueError(\"Length of data_types list does not equal number of entries in data_types dictionary.\")\n",
    "\n",
    "        if len(self.names) != len(self.spectrum_types):\n",
    "            raise ValueError(\"Length of spectrum_types list does not equal number of entries in data_types dictionary.\")\n",
    "\n",
    "        if len(self.names) != len(self.fits_keywords):\n",
    "            raise ValueError(\"Length of fits_keywords list does not equal number of entries in fits_keywords dictionary.\")\n",
    "\n",
    "        if len(self.names) != len(self.fits_comments):\n",
    "            raise ValueError(\"Length of fits_comments list does not equal number of entries in fits_comments dictionary.\")\n",
    "\n",
    "        if len(self.names) != len(self.db_columns):\n",
    "            raise ValueError(\"Length of db_columns list does not equal number of entries in db_columns dictionary.\")\n",
    "\n",
    "        keys_list = self.data_types.keys()\n",
    "        for key in keys_list:\n",
    "            dt = self.data_types[key]\n",
    "            if dt not in ['string','int','float']:\n",
    "                err_str = \"Error in data type: \" + dt\n",
    "                raise ValueError(err_str)\n",
    "\n",
    "\n",
    "    def list_qc_metrics(self):\n",
    "        \"\"\"\n",
    "        Method to print a formatted block of the available QC checks and their\n",
    "        characteristics, sorted by the data level that the QC check accepts.\n",
    "        \"\"\"\n",
    "        qc_names = self.names\n",
    "\n",
    "        for data_level in ['L0', '2D', 'L1', 'L2']:\n",
    "            print(styled_text(f\"Quality Control tests for {data_level}:\", style=\"Bold\"))\n",
    "            for qc_name in qc_names:\n",
    "\n",
    "                kpf_data_levels = self.kpf_data_levels[qc_name]\n",
    "                data_type = self.data_types[qc_name]\n",
    "                spectrum_types = self.spectrum_types[qc_name]\n",
    "                master_types = self.master_types[qc_name]\n",
    "                required_data_products = self.required_data_products[qc_name]\n",
    "                keyword = self.fits_keywords[qc_name]\n",
    "                keyword_fail_value = self.fits_keyword_fail_value[qc_name]\n",
    "                comment = self.fits_comments[qc_name]\n",
    "                db_column = self.db_columns[qc_name]\n",
    "                description = self.descriptions[qc_name]\n",
    "\n",
    "                if data_level in self.kpf_data_levels[qc_name]:\n",
    "                    print('   ' + styled_text(\"Name: \", style=\"Bold\") + styled_text(qc_name, style=\"Bold\", color=\"Blue\"))\n",
    "                    print('      ' + styled_text(\"Description: \", style=\"Bold\") + description)\n",
    "                    print('      ' + styled_text(\"Date levels: \", style=\"Bold\") + str(kpf_data_levels))\n",
    "                    print('      ' + styled_text(\"Date type: \", style=\"Bold\") + data_type)\n",
    "                    print('      ' + styled_text(\"Required data products: \", style=\"Bold\") + str(required_data_products))\n",
    "                    print('      ' + styled_text(\"Spectrum types (applied to): \", style=\"Bold\") + str(spectrum_types))\n",
    "                    print('      ' + styled_text(\"Master types (applied to): \", style=\"Bold\") + str(master_types))\n",
    "                    print('      ' + styled_text(\"Keyword: \", style=\"Bold\") + styled_text(keyword, style=\"Bold\", color='Blue'))\n",
    "                    print('      ' + styled_text(\"Keyword fail value: \", style=\"Bold\") + str(keyword_fail_value))\n",
    "                    print('      ' + styled_text(\"Comment: \", style=\"Bold\") + comment)\n",
    "                    print('      ' + styled_text(\"Database column: \", style=\"Bold\") + str(db_column))\n",
    "                    print()\n",
    "\n",
    "    def search_for_QC_keywords_in_files(self):\n",
    "        \"\"\"\n",
    "        This method checks if each QC keyword is listed in two places and\n",
    "        prints the results with green and red highlighting.  The two places\n",
    "        are: 1) .yaml plot configuration files for the time series database,\n",
    "        2) .csv files that define the time series database structure, and xxx.\n",
    "        It is best used in an interactive environment, e.g., in a Jupyter\n",
    "        notebook.\n",
    "        \"\"\"\n",
    "\n",
    "        cases = ['plots', 'database']\n",
    "\n",
    "        for case in cases:\n",
    "\n",
    "            if case == 'plots':\n",
    "                search_directory = '/code/KPF-Pipeline/static/tsdb_plot_configs/'\n",
    "                file_ext = '.yaml'\n",
    "            if case == 'database':\n",
    "                search_directory = '/code/KPF-Pipeline/static/tsdb_keywords/'\n",
    "                file_ext = '.csv'\n",
    "\n",
    "            print(styled_text(f\"Searching for *{file_ext} files in {search_directory} for QC keywords.\", style=\"Bold\"))\n",
    "            for name in self.names:\n",
    "                fits_kwd = self.fits_keywords.get(name, \"\")\n",
    "                if not fits_kwd:\n",
    "                    print(f\"Warning: No search string found for '{name}'\")\n",
    "                    continue\n",
    "                found_occurrence = False\n",
    "                for root, dirs, files in os.walk(search_directory):\n",
    "                    for file_name in files:\n",
    "                        if file_name.endswith(file_ext):\n",
    "                            full_path = os.path.join(root, file_name)\n",
    "                            # Read the file contents and check for the string\n",
    "                            with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                                content = f.read()\n",
    "                                if fits_kwd in content:\n",
    "                                    found_occurrence = True\n",
    "                                    print(styled_text(f\"Found \", color=\"Green\") + styled_text(f\"'{fits_kwd}' from '{name}'\", style=\"Bold\", color=\"Green\") + styled_text(f\" in: {full_path}\", color=\"Green\"))\n",
    "                if not found_occurrence:\n",
    "                    print(styled_text(f\"No occurrence of \", color=\"Red\") + styled_text(f\"'{name}' => '{fits_kwd}'\", style=\"Bold\", color=\"Red\") + styled_text(f\" found in any {file_ext} file.\", color=\"Red\"))\n",
    "            print()\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#\n",
    "# Superclass QC is normally not to be called directly (although it is not an abstract class, per se).\n",
    "#\n",
    "\n",
    "class QC:\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This superclass defines QC functions in general and has common methods across\n",
    "        subclasses QCL0, QC2D, QCL1, and QCL2.  It also includes QC checks that apply\n",
    "        to all data levels.\n",
    "\n",
    "    Class Attributes:\n",
    "        kpf_object: Returned from function KPF0.from_fits(fits_filename,data_type),\n",
    "            which is wrapped by function read_fits in this module.\n",
    "        qcdefinitions (QCDefinitions object): Returned from constructor of QCDefinitions class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kpf_object, logger=None):\n",
    "        self.kpf_object = kpf_object\n",
    "        self.qcdefinitions = QCDefinitions()\n",
    "        self.logger = logger if logger is not None else DummyLogger()\n",
    "\n",
    "\n",
    "    def add_qc_keyword_to_header(self, qc_name, value, debug=False):\n",
    "\n",
    "        if (str(type(value)) == \"<class 'bool'>\") or (str(type(value)) == \"<class 'numpy.bool'>\"):\n",
    "            if value == True:\n",
    "                value = 1\n",
    "            else:\n",
    "                value = 0\n",
    "\n",
    "        keyword = self.qcdefinitions.fits_keywords[qc_name]\n",
    "        comment = self.qcdefinitions.fits_comments[qc_name]\n",
    "\n",
    "        self.kpf_object.header['PRIMARY'][keyword] = (value,comment)\n",
    "        if debug:\n",
    "            print('---->add_qc_keyword_to_header: qc_name, keyword, value, comment = {}, {}, {}, {}'.format(qc_name,keyword,value,comment))\n",
    "\n",
    "\n",
    "    def not_junk(self, junk_ObsIDs_csv='/data/reference/Junk_Observations_for_KPF.csv', debug=False):\n",
    "        \"\"\"\n",
    "        This Quality Control method can be used in any of the data levels (L0/2D/L1/L2)\n",
    "        so it is included in the superclass.\n",
    "        It checks if the obsID of the input is in the list of junked files.\n",
    "\n",
    "        Args:\n",
    "             kpfobs - a KPF L0/2D/L1/L2 object\n",
    "             junk_ObsIDs_csv - a CSV with ObsIDs in the first column\n",
    "                               and a column header of 'observation_id'.\n",
    "                               That is, the first few lines of the file will look like this:\n",
    "                                   observation_id\n",
    "                                   KP.20230621.27498.77\n",
    "                                   KP.20230621.27611.73\n",
    "                                   KP.20220516.57354.11\n",
    "\n",
    "             debug - an optional flag.  If True, verbose output will be printed.\n",
    "\n",
    "         Returns:\n",
    "             QC_pass - a boolean signifying that the input(s) are not junk (i.e., = False if junk)\n",
    "        \"\"\"\n",
    "\n",
    "        QC_pass = True  # Assume not junk unless explicitly listed in junk_ObsIDs_csv\n",
    "\n",
    "        try:\n",
    "            filename = self.kpf_object.header['PRIMARY']['OFNAME'] # 'KP.20231129.11266.37.fits' / Filename of output file\n",
    "        except:\n",
    "            filename = 'this file'\n",
    "        obsID = filename[:20]\n",
    "\n",
    "        # read list of junk files\n",
    "        if os.path.exists(junk_ObsIDs_csv):\n",
    "            df_junk = pd.read_csv(junk_ObsIDs_csv)\n",
    "            if debug:\n",
    "                self.logger.info(f'Read the junk file {junk_ObsIDs_csv}.')\n",
    "        else:\n",
    "            self.logger.info(f\"The file {junk_ObsIDs_csv} does not exist.\")\n",
    "            return QC_pass\n",
    "\n",
    "        QC_pass = not (df_junk['observation_id'].isin([obsID])).any()\n",
    "        if debug:\n",
    "            self.logger.info(f'{filename} is a Junk file: ' + str(not QC_pass[i]))\n",
    "\n",
    "        return QC_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894e3271-9aa2-4313-98b3-c1a19a7aa5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QCL2(QC):\n",
    "\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This class inherits QC superclass and defines QC functions for L2 files.\n",
    "\n",
    "    Class Attributes:\n",
    "        kpf_object (astropy.io object): Returned from function KPF0.from_fits(fits_filename,data_type),\n",
    "            which is wrapped by function read_fits in this module.\n",
    "        qcdefinitions (QCDefinitions object): Returned from constructor of QCDefinitions class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Call superclass.\n",
    "    def __init__(self,kpf_object):\n",
    "        super().__init__(kpf_object)\n",
    "    \n",
    "    def L2_barycentric_rv_percent_change(self, pos_threshold=1.0, neg_threshold=-1.0, debug=False):\n",
    "        \"\"\"\n",
    "        This QC module checks the MAXPCBCV and MINPCBCV headers within the L2\n",
    "        primary headers in an L2 object. These headers represent the maximum and\n",
    "        minimum percent changes from the weighted average CCFBCV (for non-zero-\n",
    "        weight spectral orders). If an observation's maximum or minimum percent \n",
    "        change is greater or less than 1/-1% (respectively), then the method\n",
    "        returns False. \n",
    "\n",
    "        Args:\n",
    "             pos_threshold - The high percent change threshold (e.g., no orders\n",
    "                             with a percent change greater than 1%)\n",
    "             neg_threshold - The low percent change threshold (e.g., no orders\n",
    "                             with a percent change less than -1%)\n",
    "             debug - an optional flag.  If True, prints MAXPCBCV/MINPCBCV.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            L2 = self.kpf_object\n",
    "            myL2 = AnalyzeL2(L2, logger=self.logger)\n",
    "            QC_pass = True\n",
    "\n",
    "            max = myL2.Max_Perc_Delta_Bary_RV\n",
    "            min = myL2.Min_Perc_Delta_Bary_RV\n",
    "            if debug:\n",
    "                print(f\"max: {max}, min: {min}\")\n",
    "            if max > pos_threshold :\n",
    "                QC_pass = False\n",
    "                return QC_pass\n",
    "            if min < neg_threshold :\n",
    "                QC_pass = False\n",
    "                return QC_pass\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.info(f\"Exception: {e}\")\n",
    "            QC_pass = False\n",
    "\n",
    "        return QC_pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e5210b-c627-4282-9140-fd9d5c5dbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = KPF2.from_fits(\"KP.20241022.39422.56_L2_test.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1589f955-c79a-458a-a453-ea5d79bc5236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 0.6894375932041458, min: -0.47031634755679774\n"
     ]
    }
   ],
   "source": [
    "myL2 = AnalyzeL2(L2)\n",
    "print(f\"max: {myL2.Max_Perc_Delta_Bary_RV}, min: {myL2.Min_Perc_Delta_Bary_RV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f105943b-01cd-43bc-b4a8-5764dae4e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initializing AnalyzeL2 object\n",
      "max: 0.6894375932041458, min: -0.47031634755679774\n",
      "QC result: 1\n"
     ]
    }
   ],
   "source": [
    "# Test of 'L2_barycentric_rv_percent_change'\n",
    "qcl2 = QCL2(L2)\n",
    "qc_name = 'L2_barycentric_rv_percent_change'\n",
    "qc_value = qcl2.L2_barycentric_rv_percent_change(debug=True)\n",
    "qcl2.add_qc_keyword_to_header(qc_name,qc_value)\n",
    "L2_new = qcl2.kpf_object\n",
    "print('QC result: ' + str(L2_new.header['PRIMARY']['PCBCV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8285013e-dcd3-44f7-8a69-07e08f4bbd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initializing AnalyzeL2 object\n",
      "max: 0.6894375932041458, min: -0.47031634755679774\n",
      "QC result: 0\n"
     ]
    }
   ],
   "source": [
    "# Test of 'L2_barycentric_rv_percent_change'\n",
    "qcl2 = QCL2(L2)\n",
    "qc_name = 'L2_barycentric_rv_percent_change'\n",
    "qc_value = qcl2.L2_barycentric_rv_percent_change(pos_threshold=0.5, debug=True)\n",
    "qcl2.add_qc_keyword_to_header(qc_name,qc_value)\n",
    "L2_new = qcl2.kpf_object\n",
    "print('QC result: ' + str(L2_new.header['PRIMARY']['PCBCV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd8da71-4ebc-4278-8fb2-97e120216a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initializing AnalyzeL2 object\n",
      "QC result: 0\n"
     ]
    }
   ],
   "source": [
    "# Test of 'L2_barycentric_rv_percent_change'\n",
    "qcl2 = QCL2(L2)\n",
    "qc_name = 'L2_barycentric_rv_percent_change'\n",
    "qc_value = qcl2.L2_barycentric_rv_percent_change(neg_threshold=-0.4)\n",
    "qcl2.add_qc_keyword_to_header(qc_name,qc_value)\n",
    "L2_new = qcl2.kpf_object\n",
    "print('QC result: ' + str(L2_new.header['PRIMARY']['PCBCV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f166075-2608-4fd3-9465-8b8c13b2324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_barycentric_rv_percent_change(L2, pos_threshold=1.0, neg_threshold=-1.0, debug=False):\n",
    "        \"\"\"\n",
    "        This QC module checks the MAXPCBCV and MINPCBCV headers within the L2\n",
    "        primary headers in an L2 object. These headers represent the maximum and\n",
    "        minimum percent changes from the weighted average CCFBCV (for non-zero-\n",
    "        weight spectral orders). If an observation's maximum or minimum percent \n",
    "        change is greater or less than 1/-1% (respectively), then the method\n",
    "        returns False. \n",
    "\n",
    "        Args:\n",
    "             pos_threshold - The high percent change threshold (e.g., no orders\n",
    "                             with a percent change greater than 1%)\n",
    "             neg_threshold - The low percent change threshold (e.g., no orders\n",
    "                             with a percent change less than -1%)\n",
    "             debug - an optional flag.  If True, prints MAXPCBCV/MINPCBCV.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            myL2 = AnalyzeL2(L2)\n",
    "            QC_pass = True\n",
    "\n",
    "            max = myL2.Max_Perc_Delta_Bary_RV\n",
    "            min = myL2.Min_Perc_Delta_Bary_RV\n",
    "            if debug:\n",
    "                print(f\"max: {max}, min: {min}\")\n",
    "            if max > pos_threshold :\n",
    "                QC_pass = False\n",
    "                return QC_pass\n",
    "            if min < neg_threshold :\n",
    "                QC_pass = False\n",
    "                return QC_pass\n",
    "\n",
    "        except Exception as e:\n",
    "            QC_pass = False\n",
    "\n",
    "        return QC_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "844f65de-544b-4b52-8bfe-b010af7a3ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_barycentric_rv_percent_change(L2, pos_threshold=1.0, neg_threshold=-1.0, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b0e618e-09a7-4428-a242-1a3318809902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_barycentric_rv_percent_change(L2, pos_threshold=0.5, neg_threshold=-1.0, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0094ccb-c058-4133-a283-17228fe1d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_barycentric_rv_percent_change(L2, pos_threshold=1.0, neg_threshold=-0.4, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
